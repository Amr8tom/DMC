{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fZgEEPw6_tF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "!pip install tensorflow ==<2.11.0>\n",
        "print(tf.__version__)\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import glob as gb\n",
        "#from keras.models import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "import cv2\n",
        "import PIL\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from cv2 import *\n",
        "import numpy as np\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "from splitfolders.split import ratio\n",
        "#from keras import layers,datasets,models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import os\n",
        "import scipy\n",
        "import  matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "print(tf.__version__)\n",
        "\n",
        "import sklearn\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import glob\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "#for saving model\n",
        "import pickle\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Activation,Flatten,Dropout\n",
        "#from keras.models import Sequential, load_model\n",
        "from skimage.io import imread\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array ,array_to_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import requests\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading and splitting data\n",
        "#path=\"/content/drive/MyDrive/OralCancer_Last_data\"\n",
        "path=\"/content/drive/MyDrive/augmented_data\"\n",
        "\n",
        "splitfolders.ratio(path,\"after_aug\",(0.7,0.1,0.2))\n",
        "# neww data more 800 image\n",
        "# preprocessing\n",
        "# resize - re scale - normalization\n",
        "#\n",
        "# 1- data augmantation\n"
      ],
      "metadata": {
        "id": "Pp3-irydEcTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(DataFolder):\n",
        "  List_of_out=[]\n",
        "  List_of_Img_names=[]\n",
        "  binary_out=[]\n",
        "  Images=[]\n",
        "  for foldername in os.listdir(DataFolder):\n",
        "    List_of_Img_names=os.listdir(str(DataFolder)+\"/\"+str(foldername))\n",
        "    for image_name in range(len(List_of_Img_names)):\n",
        "      image=cv2.imread(os.path.join(DataFolder,foldername,List_of_Img_names[image_name]))\n",
        "      if image is not None:\n",
        "        Image=cv2.resize(image,(256,256))\n",
        "        Image=Image.astype(\"float32\")/255.\n",
        "        Images.append(Image)\n",
        "        List_of_out.append(foldername)\n",
        "  for item in List_of_out:\n",
        "    if (item=='non_cancer'):\n",
        "      binary_out.append(0)\n",
        "    if(item=='cancer'):\n",
        "      binary_out.append(1)\n",
        "  Images=np.array(Images)\n",
        "  #shuffle the data\n",
        "  #Images=random.shuffle(Images)\n",
        "  binary_out=np.array(binary_out)\n",
        "  return Images,binary_out\n",
        "X_train, Y_train = loadData(\"/content/after_aug/train\")\n",
        "X_test, Y_test = loadData(\"/content/after_aug/test\")\n",
        "X_val, Y_val = loadData(\"/content/after_aug/val\")\n"
      ],
      "metadata": {
        "id": "Bg84H_y-UjuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from cv2 import *\n",
        "def GetDatasetSize(path):\n",
        "    num_of_image = {}\n",
        "    for folder in os.listdir(path):\n",
        "        # Counting the Number of Files in the Folder\n",
        "        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n",
        "    return num_of_image;\n",
        "\n",
        "path =\"/content/drive/MyDrive/OralCancer_Last_data\"\n",
        "path2=\"/content/drive/MyDrive/augmented_data/\"\n",
        "DatasetSize = GetDatasetSize(path2);\n",
        "print(DatasetSize);\n",
        "#plt.imshow(X_train[0])\n",
        "#plt.imshow(X_test[5])\n",
        "#print(X_train[0])"
      ],
      "metadata": {
        "id": "t2rMHLR-U96b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(50,50, 3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(rate=0.25))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dropout(rate=0.5))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "model.fit(X_train,Y_train,epochs=10,validation_data=(X_val,Y_val),batch_size=64)\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "print(\"Accuracy:  %.2f%%\" % (metrics.accuracy_score(Y_test, y_pred)*100))\n"
      ],
      "metadata": {
        "id": "_KHY4DJPTU6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=X_test,y=Y_test)\n",
        "model.summary()\n",
        "#plt.imshow(X_test[1120])\n",
        "x = X_test[1120].reshape((1, ) + X_test[1120].shape)\n",
        "\n",
        "print(Y_test[1120])\n",
        "x = X_test[1120].reshape((1, ) + X_test[1120].shape)\n",
        "classes = [\"non-cancer\",\"cancer\"]\n",
        "prediction = model.predict(x)\n",
        "ind = np.argmax(prediction )\n",
        "print(classes[ind])\n",
        "#print(x.shape)s"
      ],
      "metadata": {
        "id": "6WxCsV78WO4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with open (\"model5.h5\",\"wb\") as f:\n",
        "#  pickle.dump(model,f)\n",
        "#m4y_model= load_model(\"/content/drive/MyDrive/popppp/model8.h5\")\n",
        "#m4y_model.evaluate(x=X_test,y=Y_test)\n",
        "\n",
        "print(tf.__version__)\n",
        "model.save(\"/content/drive/MyDrive/popppp/model87.tflite\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-7RRIcHfWws4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import preprocessing\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import random\n",
        "# data augmantation\n",
        "# Initialising the ImageDataGenerator class.\n",
        "# We will pass in the augmentation parameters in the constructor.\n",
        "datagen = ImageDataGenerator(\n",
        "\t\trotation_range = 20,\n",
        "\t\tshear_range = 0.2,\n",
        "\t\tzoom_range = 0.2,\n",
        "\t\thorizontal_flip = True,\n",
        "\t\tbrightness_range = (0.5, 1.5)\n",
        "\t)\n",
        "\n",
        "def augmantation(DataFolder,save_path1,save_path2):\n",
        "  List_of_out=[]\n",
        "  List_of_Img_names=[]\n",
        "  binary_out=[]\n",
        "  Images=[]\n",
        "  for foldername in os.listdir(DataFolder):\n",
        "    List_of_Img_names=os.listdir(str(DataFolder)+\"/\"+str(foldername))\n",
        "    for image_name in range(len(List_of_Img_names)):\n",
        "      image= load_img(os.path.join(DataFolder,foldername,List_of_Img_names[image_name]))\n",
        "      #image=cv2.imread(os.path.join(DataFolder,foldername,List_of_Img_names[image_name]))\n",
        "      if image is not None:\n",
        "        x = image\n",
        "        List_of_out.append(foldername)\n",
        "\n",
        "        # Converting the input sample image to an array\n",
        "        # Reshaping the input image\n",
        "        x=img_to_array(x)\n",
        "        x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "        # Generating and saving 3 augmented samples\n",
        "        # using the above defined parameters.\n",
        "        i = 0\n",
        "        for item in List_of_out:\n",
        "          if (item=='non-cancer'):\n",
        "            for batch in datagen.flow(x, batch_size = 1,\n",
        "                        save_to_dir =save_path1,\n",
        "                        save_prefix ='image', save_format ='jpg'):\n",
        "              i += 1\n",
        "              if i > 3:\n",
        "                break\n",
        "          if(item=='cancer'):\n",
        "            for batch in datagen.flow(x, batch_size = 1,\n",
        "                        save_to_dir =save_path2,\n",
        "                        save_prefix ='image', save_format ='jpg'):\n",
        "              i += 1\n",
        "              if i > 3:\n",
        "                break\n",
        "augmantation(\"/content/drive/MyDrive/OralCancer_Last_data\",\"/content/drive/MyDrive/augmented_data/non_cancer\",\"/content/drive/MyDrive/augmented_data/cancer\")"
      ],
      "metadata": {
        "id": "MszvbjsJHLFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9TroMjtamTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#def Augmantation (Image,Folder_path):\n",
        "# Loading a sample image\n",
        "image=cv2.imread(\"/content/drive/MyDrive/OralCancer_Last_data/non-cancer/12654650-6954555-image-a-22_1556101508834-Edited.jpg\")\n",
        "#img = load_img('')\n",
        "print(img)\n",
        "# Converting the input sample image to an array\n",
        "x = img_to_array(img)\n",
        "print(x)\n",
        "\n",
        "# Reshaping the input image\n",
        "x = x.reshape((1, ) + x.shape)\n",
        "\n",
        "# Generating and saving 5 augmented samples\n",
        "# using the above defined parameters.\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size = 1,\n",
        "\t\t\t\t\t\tsave_to_dir ='/content/ff',\n",
        "\t\t\t\t\t\tsave_prefix ='image', save_format ='jpeg'):\n",
        "\ti += 1\n",
        "\tif i > 5:\n",
        "\t\tbreak\n"
      ],
      "metadata": {
        "id": "N_gUwDJzkafo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LfR0_JPshv0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yKHplWJsEWBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wmYGQaHO8gdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow\n"
      ],
      "metadata": {
        "id": "bDuAeWOe9tv8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}